# 알고리즘 12주차-1

14)
지금까지 그래프 G에 대한 transitive closure를 찾는 알고리즘을 살펴보았다.

플로이드 워셜 알고리즘을 조금만 변경하면 All-Pairs Shortest Path 문제도 해결할 수 있다.

shortest기 때문에 인풋 그래프는 weighted 그래프이다

모든 정점 쌍에 대한 shortest distance를 구한다.

n번의 다익스트라 알고리즘을 사용하면 해결할 수 있지만,
다익스트라는 not negative edge만 사용가능했다. heap을 사용했을 때 O(m logn) time 이었다.
모든 버텍스에 대해서 시작버텍스로 두고 다익스트라를 n번 수행하면 O(nm logn) time에 풀 수 있다.

그래프가 dense하다면,
![알고리즘 12주차-1](images/알고리즘%2012주차-1.png)

이렇게 될것.

그러나 프로이드 워셜 알고리즘을 사용하면 log n을 제거해줄 수 있다.
![알고리즘 12주차-1-1](images/알고리즘%2012주차-1-1.png)

15) -> pdf에는 여기부터 왜없지?
예제를 통해 알고리즘을 살펴보자

자기자신으로 가는 엣지는 없기때문에 weight를 0으로 초기화,
모든 정점에 대해서, 각 정점으로부터 다른 정점까지의 거리를 초기화
![알고리즘 12주차-1-2](images/알고리즘%2012주차-1-2.png)

undirected 그래프에 대한 adjacency matrix를 표현한 것.
G0로 카피

A 버텍스로 갈 수 있는 shortest path -> D1
B 버텍스로 갈 수 있는 shortest path -> D2
…
I 버텍스로 갈 수 있는 shortest path -> D9 까지 계산해주면 된다.

이 역시 프로이드-워셜과 똑같이 진행된다.
첫번째는 버텍스 A를 통해 갈 수 있는 최단거리를 계산
첫번째 컬럼을 위에서 아래로 스캔하고, 갈 수 있는 버텍스가 존재하면, 해당 row를 업데이트

B->A로 갈 수 있다
A행 스캔.
B칸이 2지만 자기자신이니까 패스.
F칸이 9. B->A = 2, A->F = 9 이므로 B->F = 11인데, 기존의 값은 무한대이니까 새로 찾은 경로가 더 짧으므로 11로 업데이트
G칸이 5로 존재하지만, A를 통해서 가는 2+5는 원래 6보다 크므로 업데이트 X
![알고리즘 12주차-1-3](images/알고리즘%2012주차-1-3.png)

다시 컬럼을 쭉 탐색한다.
F칸에 숫자가 있으므로 A행 스캔.

위와 같은 방식으로 F행에 업데이트할 게 있으면 업데이트.
![알고리즘 12주차-1-4](images/알고리즘%2012주차-1-4.png)

+)플로이드 워셜 알고리즘도 path를 찾을 수 있지만, 복잡하기 때문에 강의에서는 생략

다음 G에 값이 있기때문에, 다시 A행 스캔후 G행 업데이트
![알고리즘 12주차-1-5](images/알고리즘%2012주차-1-5.png)

=> phase1 끝.

phase2에서도 마찬가지로, B열을 위에서부터 아래로 스캔.
버텍스 B를 통해서 갱신할 수 있는 shortest distance를 업데이드 해준다.

A칸에 값이 있다(A->B로 갈 수 있다)
B행 스캔후 A행 업데이트

.
.
.

=> phase2 (D2에 대한 수행) 끝

…
이렇게 D9(phase 9까지 진행하면 되겠다)

프로이드 워셸의 시간복잡도를 분석.

n번의 phases 수행 -> O(n)
각 phase에서 컬럼을 쭉 스캔 -> O(n)
값이 있으면 해당 row를 스캔하는데 -> O(n)

=> 총 O(n^3) time
![알고리즘 12주차-1-6](images/알고리즘%2012주차-1-6.png)

+)
![알고리즘 12주차-1-7](images/알고리즘%2012주차-1-7.png)

Ch.10 Dynamic Programming
그리디 알고리즘과 같이 최적화 문제를 푸는 기법중 하나.
촤적화 문제 = optimazation problem
지난 시간에 풀었던  -minimum spanning tree problem
-shortest path problem
-all-pairs shortest path problem
이 있었고, 지금 까지 그리디알고리즘을 이용한 방법을 사용했었고,
all-pairs shortest path problem를 DP를 같이 사용한 방법 이었다.

DP기법.
그리디 알고리즘과 유사하게 DP는 최적화 문제를 해결할 수 있는(항상 해결이아닌, 해결할 수 있는)기법 중 하나.
문제를 해결하는 방식은 Divide and conquer와 유사하다. 우리가 풀고하자하는 문제를 여러개의 subproblem으로 쪼개서 서브문제를 해결하는 방식.
차이점이있다면, divide-and-conquer는 중복된 계산을 할 수 있는데,
DP는 컴퓨터의 메모리를 더 사용해서 중복된 계산을 하지않게 함으로써 문제를 더 빨리 해결할 수 있게 한다. 즉 서브문제의 솔루션들을 메모리에 저장해놓고 같은, 기존에 저장되어있던 서브문제를 만났을 때 다시 푸는게 아니라 저장한 메모리에서 해를 탐색해서 그것을 이용해서 문제를 푼다.

DP는 크게 2가지 방법으로 분류할 수 있다
1. Top-down 방법 recursion을 사용. original problem를 충분히 작아질때 까지 쪼갠다음에, 그 문제를 풀고, 메모리 상에 저장하고, 같은 문제를 만났을 때 메모리의 저장된 해를 이용  -> 이러한 점 때문에 Top-down을 meomization 방법이라고도 한다.

![알고리즘 12주차-1-8](images/알고리즘%2012주차-1-8.png)

1. Bottom-up 방법 loop를 사용. 처음부터 문제를 쪼개진 상태로 보고, 작은 문제를 풀면서 그 솔루션를 합쳐가면서 큰 문제로 만들어가느냐.

예에 대해서 뒤에서 구체적으로 살펴보자

2)
Dynamic Programming Version of A Recursive Algorithm
-> Recursive이기때문에 top-down이겠구나 파악할 수 있다.

핵심적인 내용은
메모리(space)를 사용하므로써(서브 프로블럼을 저장하므로써) 스피드와 스페이스를 trade한다.
같은 문제를 만났을 때 다시 계산하는게 아니라, 메모리에 저장된 값을 이용.
이 서브프로블럼의 솔루션을 ‘dictionary’라고하는 자료구조에 저장할 수 있다. 여기서는 그러한 솔루션을 저장할 테이블을 soln이라고 부르겠다. 여기에다 처음 만난 서브프로블럼의 해를 저장.

Q라고 하는 서브프로블럼을 만났을 때, recursive call을 하기 전에 딕셔너리 soln을 체크한다.
저장되어있지 않으면, recursive call을 진행한다. 저장되어있으면 -> 저장되어있는 솔루션을 이용하고, recursive call을 하지 않는다.

솔루션을  리턴하기전에 soln에 값을 저장한다.

3)
예제를 통해서 DP의 개념을 살펴보자.

탑다운 방식으로 피보나치를 해결하는 방법은, 다음의 점화식을 이용한다.
![알고리즘 12주차-1-9](images/알고리즘%2012주차-1-9.png)

f10을 구한다고 가정했을때, soln에 계산된 값이 없다면,
다음과 같이 재귀적으로 계산이 들어갈 것이다.
![알고리즘 12주차-1-10](images/알고리즘%2012주차-1-10.png)

한번 계산된 값은 soln에 저장해서, 같은 문제를 만나면 다시 계산하지 않고 사용.

…
![알고리즘 12주차-1-11](images/알고리즘%2012주차-1-11.png)

이것은 top-down 방식인데

bottom-up으로도 해결할 수 있다.
![알고리즘 12주차-1-12](images/알고리즘%2012주차-1-12.png)

k번째 루프라 수행될 때, k보다 작은 index에 대해서는 이미 값 계산이 되었기 때문에 재귀적으로 들어갈 필요가 없게된다.

4)
본격적으로 살펴볼 문제
Matrix-Chain Multiplication 문제.

인풋으로 n개의 매트릭스가 입력

해결하고싶은 문제는 어떤 순서로 행렬들을 곱해야 곱셈연산의 수가 최소가 되는지.

행렬은 결합법칙이 성립한다.
![알고리즘 12주차-1-13](images/알고리즘%2012주차-1-13.png)

그러나 곱셈의 순서에 따라 연산의 수가 달라진다.

이 문제를 Matrix-Chain Multiplication 문제라고 한다.
DP로 풀기 때문에 optimization problem이다.

문제의 인풋으로는 n개의 매트릭스가 주어질 수 있지만,
다음과같이 매트릭스의 차원만 주어질 수 도 있다.(차원만 알도 연산의 수를 구할수 있으니까.)
![알고리즘 12주차-1-14](images/알고리즘%2012주차-1-14.png)

중요한것은 scalar multiplication의 수를 최소화 하는 것

5)
계산시간에 대해 알아보자

p x q인 행렬 A
q x r인 행렬 B가 있을 때,
![알고리즘 12주차-1-15](images/알고리즘%2012주차-1-15.png)

곱의 결과로 생긴 C행렬은 p x r이고, 각각의 원소들은 q번의 scalar 곱셈이 필요하다.

따라서 총 pqr의 scalar multiplication이 걸린다.

예제로 다음과같이 4개의 매트릭스가 주어졌다고 가정해보자.
차원만 주어져도 된다.
-> 곱셈 연산의 수가 최소가되는 곱셈 순서를 알고 싶은 것.
![알고리즘 12주차-1-16](images/알고리즘%2012주차-1-16.png)

문제에 때라서 optimal solution의 value만 필요할 수도 있고,
곱셈순서인 optimal solution 도 필요할 수 있다.

6)
개발과정.
Dynamic Programming을 이용해서 문제를 풀 때 공통적으로 수행되는 단계.

1. 문제의 특성을 파악
2. 점화식을 세운다.
3. 점화식을 이용하여 optimal solution의 값을 계산한다. 바텀업 또는 탐다운

+) optional
1. 필요하다면 계산하는 정보를 이용하여, optimal solution을 계산.

7)
Matrix-Chain Multiplication 문제에 대해 각각의 스텝을 살펴보자

스텝1. optimal solution의 구조 파악하기

어떤 식으로 괄호를 만들어줘야 곱셈의 수를 최소화 할지.

Ai…Aj까지의 매트릭스의 chain이 주어졌을 때
Ai…Ak, Ak+1,.. Aj로 나눌 수 있다.
각각의 결과값을 이용하여 행렬곱을 할 수 있다.
i <= k < j가 될 수 있다.

결과는
![알고리즘 12주차-1-17](images/알고리즘%2012주차-1-17.png)

이렇게 되는데, k에 대해 곱셈연산의 수가 최소가 되어야한다.

모든 가능한 경우를 쪼개서 최적의 위치, 즉 k가 되는 곳을 찾아야한다.

8)
스텝 2. 점화식 정의
m테이블 - 매트릭스 Chain에 대해 곱셈연산의 최소 회수를 계산할 때 필요한 테이블
s테이블 - Ai~Aj의 매트리스 체인이 주어졌을때, 곱셈연산을 최소로하는 k값을 계산하는 테이블

m은 value of an optimal solution을 저장하는거고,
s은 optimal solution을 저장하는 테이블이다.

i=j이면, 즉 행렬이 하나일 때는 -> 0 (곱셈할일이 없으므로)

i<j이면 행렬곱셈을 수행할 수 있다.
![알고리즘 12주차-1-18](images/알고리즘%2012주차-1-18.png)

이러한 가능한 k에 대해 모든 상황을 따져서 값을 가장 작게하는 k를 구하는것.
이 값은 m[i, j]가 되겠다.

행렬의 차원을 얘기할때,
Ai = pi-1 x pi 로 정의한다.
ex) A4행렬의 차원 -> A4 = p3 x p4

