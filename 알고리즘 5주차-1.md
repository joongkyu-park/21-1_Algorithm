# 알고리즘 5주차-1

40분 지각.
앞부분은 2분반 청강으로-
=================
5)
insertion소트의 인풋 아웃풋
…

insertion소트는
sort된 시퀀스와 unsort된 시퀀스로 구분한다.

최초 인덱스 0은 정렬된 영역으로보고,
인덱스 1부터 n-1까지 정렬을 시켜준다.
한번 정렬을 수행할때마다 sorted 시퀀스가 1씩늘어난다.

…

6)
shifVacRec을 살펴보자. (재귀로 구현해서 Rec이 붙음. 반복으로도 구현가능)
…
언제까지하냐
-> 나의 위치가 0이 될때까지.

7)
그림으로 한번 보자.
그림의 인덱스의 시작이 1이라고 나와있는데 0이라고 생각하자.

…

*loop invariant
수학적 귀납법과 비슷하게 분석하는 방법. 조금은 다름
크게 3가지 단계로 알고리즘의 correctness를 증명해준다.
1. Initialization 단계 그 문제에서 sub problem을 만족시켜준다. 루프의 첫번째 이터레이션이 실행되기전에 참이라고 보여준다
2. Maintenance 단계 루프에서 어떤 이터레이션이 수행되기전에 참이라면, k번째 이터레이션이 참임을 보여준다,
3. Termination 단계 (수학적 귀납법에서는 이 단계가 없지만,  알고리즘에서는 유한시간에 해결해야하기때문에 이 단계가 있다.) 모든 이터레이션이 종료되었을때, 알고리즘이 정확히 수행되었음을 보여준다. 참이라는것을 보여준다. -> insertion sort에서는 루프가 종료되면 오름차순으로 정렬되어있어야함

insertion sort에 적어요
1. 초기화 인덱스가 0인 부분이 sorted되어있다
2. 유지보수 임의의 이터레이션이 시작되기전에 왼쪽의영역이 sorted 시퀀스라고 가정하면, 이터레이션이 수행되고나서도 된다.
3. 종료 모든 엘리먼트들이 sorted 시퀀가 만족된다.

=> 알고리즘의 correctness를 이런식으로 증명할 수 있다.

8)
알고리즘의 효율성을 분석해보자

워스트케이스부터.
매 이터레이션마다 해당원소가 가장 가장작은값일때.
-> 즉 인풋이 내림차순으로 주어졌을때.
여기서 basic operation은 엘리먼트간의 비교연산.

처음에 인덱스가1일때 1번비교,
2일때 2번비교,
… 인덱스가 i일때 i번비교
![알고리즘 5주차-1](images/알고리즘%205주차-1.png)

따라서 최악의경우의 시간복잡도는 쎄타오브(n^2)이다.

평균수행시간보자.
앞에서의 평균수행시간과의 차이를 보자.
n개의 원소가 있었을 때 k값을 찾는문제는 k값이 있을확률, 없을확률로 나누었다.

근데 이건 정렬자체는 무조건 성공하기때문에, 그 경우만 따져주면된다.
(문제에따라 성공,실패 확률나눌수도있고 아닐수도있다.)

i=5라고해보자
인덱스 i의 원소 x가 있을때
x의 위치가 5라면 1번비교가 필요,
4라면 2번비교가 필요,
3이라면 3번비교가 필요..
..
1이라면 5번비교(i번비교가 필요)
	=> 이경우들이 총 i개 cases

인덱스가 0이라면(가장 작았다면) 이때도 5번의 비교
	=> 이경우는 1개의 case
이유?
![알고리즘 5주차-1-1](images/알고리즘%205주차-1-1.png)

![알고리즘 5주차-1-2](images/알고리즘%205주차-1-2.png)

따라서 평균적인 수행시간을 분석하기 위해서,
i+1개의 케이스가 있고, 발생할 확률은 모두 같다고 가정 : 1/(i+1)

…내용참고

따라서 A(n)은 n^2/4 에 근사, -> 세타오브(n^2)

따라서 워스트케이스에서도, 에버리지케이스에서도 세타오브(n^2) 이더라.
조금더 디테일하게보면 워스트케이스의 계수는 1/2, 에버리지케이스는 1/4

9)
insertion 소트의 optimality
어떤 특정한 경우에는 optimal 알고리즘이 될 수 있다.
	-> 인접한 엘리먼트끼리만 비교연산 또는 데이터의 swap을 허용할 경우

어떤 경우 이런경우가 발생하느냐?
hdd나 ssd는 random access가 허용됨 
	-> 랜덤한 위치의 인덱스의 값을 비교해도 상수시간에 비교가능(이론적으로)
마그네틱테이프(카세트테이프)처럼 순차접근만 가능한 저장장치
	-> 인접해있는 데이터끼리만 비교가능 (상수시간에 비교하려면)
	-> 이런경우에 insertion sort가 최적일 수 있겠다.

그러나 이와같은경우는 요즘 거의없기때문에..
일반적으로는 best 알고리즘이라고 할 수 없겠다.

10)
퀵소트를 살펴보자.
최악의경우 O(n^2)으로 인서션소트와 같지만
평균경우 O(nlog(n))으로 인서션소트보다 빠르다.

11)
퀵소트 알고리즘은 2개의 전략을 사용
첫번째 전략, divide and conquer 전략
문제를 해결하는 전략중 하나.

큰 문제하나를 여러 작은 문제로 나누어서 해결하는 전략.

크게 3가지스텝
1. divde 단계 문제는 같지만 크기가 작은 여러개의 sub prolblem으로 쪼갠다
2. conquer 단계 원하는 사이즈만큼 문제가 쪼개졌으면, 그 문제를 재귀적(또는 반복적으로)해결
3. combine 단계 원래의 문제의 솔루션을 얻기위해 작은 문제들의 솔루션을 combine

ppt의 수도코드에서 인자 I는 input을 의미

12)
퀵소트 알고리즘을 본격적으로 보자.

위에서 말한대로 2가지 전략이용. 1. divide and conquer  2. 그 안에서 randomization 	input으로 들어온 n개의 엘리먼트중에 기준이 되는 엘리먼트를 선택. 	이를 pivot이라고 부름.
	pivot을 선택할때 랜덤하게 선택
	pivot을 기준으로 3개의 그룹으로 나눔

원래 인풋에서 3개의 그룹으로 나눈다.
L, E, G 그룹 
말이 3개지 원래 2개의 그룹, E는 1개의 엘리먼트
실제로 반복적으로 수행할그룹은 L, G 그룹

pivot이라부르는 1개의 원소 선택.
인풋사이즈 n에 대해서 랜덤하게.
그걸 x라고 했을때
x보다 키값이 작은걸 L그룹,
같은그룹을 E그룹,
큰그룹을 G그룹으로
-> divide전략

conquer : L, G그룹에 대해서만 수행
->이유? pivot을 하나 선택하고 나서,
L그룹이 x보다작고 G그룹이 x보다 크기 때문에
최종정렬이후에도 x의 위치는 L그룹과 G그룹사이에있음. -> 최종적인 정렬된 위치를 찾았다

L, G그룹에 대해서 또 재귀적으로 L,E,G그룹로 나누어서 디바이드 앤 컨쿼 진행.
![알고리즘 5주차-1-3](images/알고리즘%205주차-1-3.png)

이렇게 하다보면 결론적으로 오름차순으로 정렬

13)
divide에 사용되는 함수이름
-> partition
L, E, G 그룹으로 나눔

인풋 : 시퀀스 s, 포지션 p인 피봇(p는 배열로따지면 인덱스같은것. 피봇은 랜덤하게 선택됨)
아웃풋 : L, E, G그룹이 나눠진 상태로 출력
	-> 각각을 서로다른 시퀀스로 출력
	(여기서 구현을이렇게 한거고 반드시 이렇게 하란건아니다.)

S가 empty일때까지 수행.
모든원소를 피봇인 x와 비교하여 L,E,G중 하나에 insert시켜준다.

구현적으로 봤을때, 시퀀스의 시작점이나 끝위치에서 삽입하거나 삭제하는건
상수시간에 수행할 수 있다. (?)
-> n개의 엘리먼트에 대해 수행하기 때문에 O(n)시간이 걸린다.

14)
퀵소트 알고리즘의 워스트케이스의 수행시간

피봇을 랜덤하게 선택하는데,
피봇의 키값이 가장 작은 엘리먼트이거나 가장큰 엘리먼트인 경우.
-> 이때가 워스트케이스
-> L그룹이나 G그룹중하나가 n-1개, 나머지하나가 0개가 되는 경우

G그룹이 n-1이라고 가정. (피봇의 값이 최소값이라고 가정)

처음에 데이터가 n개가 있을때
피봇이 최소값이라고 가정. -> n번의 비교  연산을 통해 G그룹임을 알 수 있다
그 다음엔 n-1번의 비교를해야함
…
마지막에 사이즈가 2였을때 1번 비교하면서 끝.
=> 비교연산의 회수 : n+ (n-1) + … + 2 + 1
따라서 퀵소트의 최악의 경우 수행시간은 O(n^2)

*여기서 내용에 없는 부분
스샷참고
quick sort의 average case analysis가 O(nlong(n))에 수행된다고 하였다.
이것에대해 informal하게 분석해보자.

최악의경우에는 divide할때 피봇이 가장크거나 가장작은경우 였다.
베스트케이스라면?
항상 가장 가운데의 값을 피봇으로 선택할때.

그럼 에버리지케이스라면?
best와 worst의 중간정도의 위치가 average라고 볼 수 있겠다. (1/4이나 3/4지점)
-> 전체사이즈가 n이라고했을때, 한쪽의 크기는 1/4n크기, 한쪽의크기는 3/4n크기라고하고 분석

L이 항상 1/4크기, G가 3/4 크기라고 가정하자

재귀적으로 divdide를 하기 때문에 tree를 이용하여 분석해볼 수 있다 (recursion tree)

모든 레벨에서 divide하는 연산의 수는 o(n)으로 같다고 볼 수 있다 (partition 함수)
![알고리즘 5주차-1-4](images/알고리즘%205주차-1-4.png)

-> 이 트리의 height, 즉 재귀가 가장 깊게들어가는 맨오른쪽 path를 분석해주면된다.

이해를 위해 가장 짧은 path를 살펴보자.
![알고리즘 5주차-1-5](images/알고리즘%205주차-1-5.png)

위와 같이 log4(n)이라고 할 수 있다.

그럼 가장 긴 path는
![알고리즘 5주차-1-6](images/알고리즘%205주차-1-6.png)

위와같이 분석할 수 있다.

따라서 재귀한번당 파티션의 연산이 O(n)이므로
결론적으로
![알고리즘 5주차-1-7](images/알고리즘%205주차-1-7.png)

이 퀵소트 알고리즘의 평균수행시간이 된다.

이 방법대로 분석하면 1/4, 3/4으로 쪼개지않고
1/100/ 99/100으로 쪼개도 결국 쎄타(lg n)에 바운드 된다.

